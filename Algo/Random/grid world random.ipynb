{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76628efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a86a928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'        for i in grid:\\n            print(i)\\n        print(\"\\n\")'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GridWorld:\n",
    "    def __init__(self, taille, position_start, good_end_position, bad_end_position):\n",
    "        self.current_state = position_start  # État actuel (ligne, colonne)\n",
    "        self.states = [[x, y] for x in range(taille[0]) for y in range(taille[1])]\n",
    "        self.end_good_state = good_end_position  # État final (ligne, colonne)\n",
    "        self.end_bad_state = bad_end_position\n",
    "        self.grid_size = taille  # Taille de la grille (lignes, colonnes)\n",
    "        self.stateSpace = {}\n",
    "        self.matchStates()\n",
    "        self.num_actions = 4  # Nombre total d'actions possibles (haut, bas, gauche, droite)\n",
    "        self.reward = 0  # Récompense actuelle\n",
    "        self.done = False  # Indique si la partie est terminée\n",
    "        self.generate_grid()\n",
    "        self.actions = [2, 3, 0, 1]\n",
    "        self.rewards = [0, 1, 3]\n",
    "        self.actionSpace = {0: -self.grid_size[0], 1: self.grid_size[0],\n",
    "                            2: -1, 3: 1}\n",
    "        self.P = {}\n",
    "        self.initP()\n",
    "    \n",
    "    def matchStates(self):\n",
    "        i=0\n",
    "        for s in self.states:\n",
    "            self.stateSpace[str(s)] = i\n",
    "            i = i+1\n",
    "    \n",
    "    def getStateInt(self, st):\n",
    "        return self.stateSpace[str(st)]\n",
    "    \n",
    "    def getStateCouple(self, st):\n",
    "        n_state = {i for i in self.stateSpace if self.stateSpace[i]==st}\n",
    "        return list(n_state)\n",
    "        \n",
    "    def initP(self):\n",
    "        for state in self.states:\n",
    "            st = self.getStateInt(state)\n",
    "            for action in self.actions:\n",
    "                self.current_state = state\n",
    "                state_, reward_, done_ = self.step(action)\n",
    "                stt = self.getStateInt(state_)\n",
    "                self.P[(stt, reward_, st, action)] = 1\n",
    "\n",
    "    \n",
    "    def step(self, action):\n",
    "        if action == 0:\n",
    "            if self.current_state[0] == 0 :\n",
    "                self.current_state[0] = self.grid_size[0] - 1\n",
    "                self.reward = 0  # Pas de récompense pour traverser le mur\n",
    "                self.generate_grid()\n",
    "                self.endgame()\n",
    "            else:\n",
    "                self.current_state[0] = self.current_state[0] - 1\n",
    "                self.reward = 0  # Pas de récompense pour avancer\n",
    "                self.generate_grid()\n",
    "                self.endgame()\n",
    "\n",
    "        elif action == 1:\n",
    "            if self.current_state[0] == self.grid_size[0] - 1:\n",
    "                self.current_state[0] = 0\n",
    "                self.reward = 0  # Pas de récompense pour avancer\n",
    "                self.generate_grid()\n",
    "                self.endgame()\n",
    "            else :\n",
    "                self.current_state[0] = self.current_state[0] + 1\n",
    "                self.reward = 0  # Pas de récompense pour avancer\n",
    "                self.generate_grid()\n",
    "                self.endgame()\n",
    "\n",
    "        elif action == 2:\n",
    "            if self.current_state[1] == 0:\n",
    "                self.current_state[1] = self.grid_size[1] - 1\n",
    "                self.reward = 0  # Pas de récompense pour avancer\n",
    "                self.generate_grid()\n",
    "                self.endgame()\n",
    "            else:\n",
    "                self.current_state[1] = self.current_state[1] - 1\n",
    "                self.reward = 0  # Pas de récompense pour avancer\n",
    "                self.generate_grid()\n",
    "                self.endgame()\n",
    "\n",
    "        elif action == 3:\n",
    "            if self.current_state[1] == self.grid_size[1] - 1:\n",
    "                self.current_state[1] = 0\n",
    "                #print(self.current_state)\n",
    "                self.reward = 0  # Pas de récompense pour avancer\n",
    "                self.generate_grid()\n",
    "                self.endgame()\n",
    "            else:\n",
    "                self.current_state[1] = self.current_state[1] + 1\n",
    "                self.reward = 0  # Pas de récompense pour avancer\n",
    "                self.generate_grid()\n",
    "                self.endgame()\n",
    "                # Si l'on atteint l'état final, la partie est terminée\n",
    "        return self.current_state, self.reward, self.done\n",
    "\n",
    "    def endgame(self):\n",
    "        if self.current_state == self.end_good_state:\n",
    "            self.reward = 1  # Récompense de 1 pour atteindre l'état final\n",
    "            self.done = True\n",
    "        elif self.current_state == self.end_bad_state:\n",
    "            self.reward = 3\n",
    "            self.done = True\n",
    "\n",
    "    # def update_grid(self):\n",
    "    #     new_grid = [[\"_\", \"_\", \"_\", \"_\"],\n",
    "    #                 [\"_\", \"_\", \"_\", \"_\"],\n",
    "    #                 [\"_\", \"_\", \"_\", \"_\"],\n",
    "    #                 [\"_\", \"_\", \"_\", \"_\"]]\n",
    "    #     new_grid[self.current_state[0]][self.current_state[1]] = \"X\"\n",
    "    #     for i in new_grid:\n",
    "    #         print(i)\n",
    "\n",
    "    def generate_grid(self):\n",
    "        grid=[]\n",
    "        for i in range(self.grid_size[0]):\n",
    "            grid.append([])\n",
    "            for j in range(self.grid_size[1]):\n",
    "                grid[i].append(\"_\")\n",
    "        grid[self.current_state[0]][self.current_state[1]] = \"X\"\n",
    "\"\"\"        for i in grid:\n",
    "            print(i)\n",
    "        print(\"\\n\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19825620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_policy(grid, V, policy, discount_factor=0.9):\n",
    "    theta=1e-6\n",
    "    #Initialize the Value function \n",
    "    #V = np.zeros((world.grid_size[0],world.grid_size[1]))\n",
    "    \n",
    "    while True:\n",
    "        DELTA = 0\n",
    "        for s in grid.states:\n",
    "            i = s[0]\n",
    "            j = s[1]\n",
    "            m_state = grid.getStateInt(s)\n",
    "            old_V = V[i][j]\n",
    "            weight = 1 / len(policy[m_state])\n",
    "            for action in policy[m_state]:\n",
    "                total = 0\n",
    "                for key in grid.P:\n",
    "                    (newState, reward, oldState, act) = key\n",
    "                    n_state = list(grid.getStateCouple(newState)[0])\n",
    "                    n_state = [int(n_state[1]), int(n_state[4])]\n",
    "                    if oldState == m_state and act == action:\n",
    "                        total += weight*grid.P[key]*(reward+discount_factor*V[n_state[0]][n_state[1]])\n",
    "            V[i][j] = total\n",
    "            DELTA = max(DELTA, np.abs(old_V-V[i][j]))\n",
    "            \n",
    "        if DELTA < theta:\n",
    "            return V            \n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9040386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_improvement(grid, V, policy, discount_factor=0.9):\n",
    "    policy_stable = True\n",
    "    newPolicy = {}\n",
    "    for s in grid.states:\n",
    "        i = s[0]\n",
    "        j = s[0]\n",
    "        m_state = grid.getStateInt(s)\n",
    "        old_actions = policy[m_state]\n",
    "        value = []\n",
    "        newAction = []\n",
    "        for action in old_actions:\n",
    "            total = 0\n",
    "            weight = 1 / len(policy[m_state])\n",
    "            for key in grid.P:\n",
    "                (newState, reward, oldState, act) = key\n",
    "                n_state = list(grid.getStateCouple(newState)[0])\n",
    "                n_state = [int(n_state[1]), int(n_state[4])]\n",
    "                if oldState == m_state and act == action:\n",
    "                    total += weight*grid.P[key]*(reward+discount_factor*V[n_state[0]][n_state[1]])\n",
    "                    value.append(np.round(total, 2))\n",
    "                    newAction.append(action)  \n",
    "                    \n",
    "        value = np.array(value) #Get the list of gotten value actions in the current state\n",
    "        print(value)\n",
    "        best = np.where(value == value.max())[0] #Get the position of the best gotten value action\n",
    "        bestActions = [newAction[item] for item in best]\n",
    "        newPolicy[m_state] = bestActions\n",
    "        \n",
    "        if old_actions != bestActions:\n",
    "            policy_stable = False\n",
    "    return policy_stable, newPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c120cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_iteration(grid, discount_factor=0.9):\n",
    "    \n",
    "    #Initialize the policy\n",
    "    V = np.random.random((world.grid_size[0],world.grid_size[1]))\n",
    "    policy = {}\n",
    "    for state in grid.stateSpace.values():\n",
    "        # equiprobable random strategy\n",
    "        policy[state] = grid.actions\n",
    "    print(\"Policy : \")\n",
    "    print(policy)\n",
    "    V = evaluate_policy(grid, V, policy, discount_factor=0.9)\n",
    "    print(\"V = \")\n",
    "    print(V)\n",
    "    \n",
    "    policy_stable = False\n",
    "    while not policy_stable:\n",
    "        old_policy = policy.copy()\n",
    "        \n",
    "        print(\"Start of policy evaluation\")\n",
    "        #Evaluate the policy\n",
    "        V = evaluate_policy(grid, V, policy, discount_factor=0.9)\n",
    "        print(\"V = \")\n",
    "        print(V)\n",
    "        \n",
    "        print(\"Start of policy Improvement\")\n",
    "        #Improve the policy\n",
    "        policy_stable, policy =  policy_improvement(grid, V, policy, discount_factor=0.9)\n",
    "        print(\"Policy : \")\n",
    "        print(policy)\n",
    "    \n",
    "        \"\"\"if all(old_policy[s] == policy[s] for s in grid.stateSpace.values()):\n",
    "            break\"\"\"\n",
    "            \n",
    "    return policy\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d54f6e4f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy : \n",
      "{0: [2, 3, 0, 1], 1: [2, 3, 0, 1], 2: [2, 3, 0, 1], 3: [2, 3, 0, 1], 4: [2, 3, 0, 1], 5: [2, 3, 0, 1], 6: [2, 3, 0, 1], 7: [2, 3, 0, 1], 8: [2, 3, 0, 1], 9: [2, 3, 0, 1], 10: [2, 3, 0, 1], 11: [2, 3, 0, 1], 12: [2, 3, 0, 1], 13: [2, 3, 0, 1], 14: [2, 3, 0, 1], 15: [2, 3, 0, 1]}\n",
      "V = \n",
      "[[3.86984890e-08 1.06753905e-08 4.28072624e-08 3.72312549e-08]\n",
      " [4.78176845e-08 9.26446916e-09 6.77027128e-08 2.54488514e-08]\n",
      " [2.68108143e-08 2.02997422e-08 5.81140686e-08 9.67741907e-01]\n",
      " [6.29358892e-08 3.55409736e-08 2.11727409e-08 3.22580681e-01]]\n",
      "Start of policy evaluation\n",
      "V = \n",
      "[[8.70716002e-09 2.40196287e-09 9.63163404e-09 8.37703236e-09]\n",
      " [1.07589790e-08 2.08450556e-09 1.52331104e-08 5.72599156e-09]\n",
      " [6.03243322e-09 4.56744200e-09 1.30756654e-08 9.67741929e-01]\n",
      " [1.41605751e-08 7.99671907e-09 4.76386670e-09 3.22580653e-01]]\n",
      "Start of policy Improvement\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0.   0.   0.32 0.  ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0.97 0.   0.   0.  ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0.   0.97 0.   0.97]\n",
      "[0.32 0.   0.   0.  ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0.   0.32 0.97 0.32]\n",
      "Policy : \n",
      "{0: [2, 3, 0, 1], 1: [2, 3, 0, 1], 2: [2, 3, 0, 1], 3: [0], 4: [2, 3, 0, 1], 5: [2, 3, 0, 1], 6: [2, 3, 0, 1], 7: [2, 3, 0, 1], 8: [2], 9: [2, 3, 0, 1], 10: [2, 3, 0, 1], 11: [3, 1], 12: [2], 13: [2, 3, 0, 1], 14: [2, 3, 0, 1], 15: [0]}\n",
      "Start of policy evaluation\n",
      "V = \n",
      "[[9.62779619e-22 2.65593016e-22 1.06500178e-21 5.90909054e+00]\n",
      " [1.18965606e-21 2.30490707e-22 1.68437564e-21 6.33141916e-22]\n",
      " [5.45454505e+00 5.05037240e-22 1.44581978e-21 2.72727252e+00]\n",
      " [5.90909054e+00 8.84223802e-22 5.26756572e-22 5.45454527e+00]]\n",
      "Start of policy Improvement\n",
      "[1.33 0.   1.33 0.  ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[5.91]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0.   0.   1.33 0.  ]\n",
      "[5.45]\n",
      "[1.23 0.   0.   0.  ]\n",
      "[0. 0. 0. 0.]\n",
      "[2.73 2.73]\n",
      "[5.91]\n",
      "[1.33 0.   0.   0.  ]\n",
      "[0. 0. 0. 0.]\n",
      "[5.45]\n",
      "Policy : \n",
      "{0: [2, 0], 1: [2, 3, 0, 1], 2: [2, 3, 0, 1], 3: [0], 4: [2, 3, 0, 1], 5: [2, 3, 0, 1], 6: [2, 3, 0, 1], 7: [0], 8: [2], 9: [2], 10: [2, 3, 0, 1], 11: [3, 1], 12: [2], 13: [2], 14: [2, 3, 0, 1], 15: [0]}\n",
      "Start of policy evaluation\n",
      "V = \n",
      "[[2.65909083e+00 1.34456465e-23 5.39157153e-23 5.90909083e+00]\n",
      " [6.02263383e-23 1.16685921e-23 8.52715166e-23 5.31818175e+00]\n",
      " [5.45454537e+00 4.90909083e+00 7.31946264e-23 2.72727269e+00]\n",
      " [5.90909083e+00 5.31818175e+00 2.66670515e-23 5.45454542e+00]]\n",
      "Start of policy Improvement\n",
      "[2.66 2.66]\n",
      "[0.6 0.  1.2 0. ]\n",
      "[0. 0. 0. 0.]\n",
      "[5.91]\n",
      "[1.2 0.  0.6 0. ]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[5.32]\n",
      "[5.45]\n",
      "[4.91]\n",
      "[1.1 0.  0.  0. ]\n",
      "[2.73 2.73]\n",
      "[5.91]\n",
      "[5.32]\n",
      "[1.2 0.  0.  0. ]\n",
      "[5.45]\n",
      "Policy : \n",
      "{0: [2, 0], 1: [0], 2: [2, 3, 0, 1], 3: [0], 4: [2], 5: [2, 3, 0, 1], 6: [2, 3, 0, 1], 7: [0], 8: [2], 9: [2], 10: [2], 11: [3, 1], 12: [2], 13: [2], 14: [2], 15: [0]}\n",
      "Start of policy evaluation\n",
      "V = \n",
      "[[2.65909089e+00 4.78636361e+00 2.72948309e-24 5.90909089e+00]\n",
      " [4.78636361e+00 5.90722473e-25 4.31687053e-24 5.31818180e+00]\n",
      " [5.45454544e+00 4.90909089e+00 4.41818180e+00 2.72727272e+00]\n",
      " [5.90909089e+00 5.31818180e+00 4.78636362e+00 5.45454545e+00]]\n",
      "Start of policy Improvement\n",
      "[2.66 2.66]\n",
      "[4.79]\n",
      "[1.08 0.   1.08 0.  ]\n",
      "[5.91]\n",
      "[4.79]\n",
      "[1.08 0.   1.08 0.  ]\n",
      "[0. 0. 0. 0.]\n",
      "[5.32]\n",
      "[5.45]\n",
      "[4.91]\n",
      "[4.42]\n",
      "[2.73 2.73]\n",
      "[5.91]\n",
      "[5.32]\n",
      "[4.79]\n",
      "[5.45]\n",
      "Policy : \n",
      "{0: [2, 0], 1: [0], 2: [2, 0], 3: [0], 4: [2], 5: [2, 0], 6: [2, 3, 0, 1], 7: [0], 8: [2], 9: [2], 10: [2], 11: [3, 1], 12: [2], 13: [2], 14: [2], 15: [0]}\n",
      "Start of policy evaluation\n",
      "V = \n",
      "[[2.65909091e+00 4.78636363e+00 2.15386363e+00 5.90909091e+00]\n",
      " [4.78636363e+00 2.15386363e+00 2.18541571e-25 5.31818182e+00]\n",
      " [5.45454545e+00 4.90909091e+00 4.41818182e+00 2.72727273e+00]\n",
      " [5.90909091e+00 5.31818182e+00 4.78636363e+00 5.45454545e+00]]\n",
      "Start of policy Improvement\n",
      "[2.66 2.66]\n",
      "[4.79]\n",
      "[2.15 2.15]\n",
      "[5.91]\n",
      "[4.79]\n",
      "[2.15 2.15]\n",
      "[0.48 0.   0.48 0.  ]\n",
      "[5.32]\n",
      "[5.45]\n",
      "[4.91]\n",
      "[4.42]\n",
      "[2.73 2.73]\n",
      "[5.91]\n",
      "[5.32]\n",
      "[4.79]\n",
      "[5.45]\n",
      "Policy : \n",
      "{0: [2, 0], 1: [0], 2: [2, 0], 3: [0], 4: [2], 5: [2, 0], 6: [2, 0], 7: [0], 8: [2], 9: [2], 10: [2], 11: [3, 1], 12: [2], 13: [2], 14: [2], 15: [0]}\n",
      "Start of policy evaluation\n",
      "V = \n",
      "[[2.65909091 4.78636364 2.15386364 5.90909091]\n",
      " [4.78636364 2.15386364 0.96923864 5.31818182]\n",
      " [5.45454545 4.90909091 4.41818182 2.72727273]\n",
      " [5.90909091 5.31818182 4.78636364 5.45454545]]\n",
      "Start of policy Improvement\n",
      "[2.66 2.66]\n",
      "[4.79]\n",
      "[2.15 2.15]\n",
      "[5.91]\n",
      "[4.79]\n",
      "[2.15 2.15]\n",
      "[0.97 0.97]\n",
      "[5.32]\n",
      "[5.45]\n",
      "[4.91]\n",
      "[4.42]\n",
      "[2.73 2.73]\n",
      "[5.91]\n",
      "[5.32]\n",
      "[4.79]\n",
      "[5.45]\n",
      "Policy : \n",
      "{0: [2, 0], 1: [0], 2: [2, 0], 3: [0], 4: [2], 5: [2, 0], 6: [2, 0], 7: [0], 8: [2], 9: [2], 10: [2], 11: [3, 1], 12: [2], 13: [2], 14: [2], 15: [0]}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Il faut choisir un nombre entre 0 et 3\n",
    "    # Si l'action est 0, déplacement vers le haut\n",
    "    # Si l'action est 1, déplacement vers le bas\n",
    "    # Si l'action est 2, déplacement vers la gauche\n",
    "    # Si l'action est 3, déplacement vers la droite\n",
    "    world = GridWorld([4,4],[0,0],[3,3],[2,3]) #taille, position de départ, fin de jeu reward positive, fin de jeu reward négative\n",
    "    policy_iteration(world, discount_factor=0.9)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1670350b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%sql` not found.\n"
     ]
    }
   ],
   "source": [
    "%sql"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
